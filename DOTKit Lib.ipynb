{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bcaffc-0946-4eb5-a461-638ad51d83f1",
   "metadata": {},
   "source": [
    "# Data Observability Toolkit Library (*DOTKit Lib*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e65d3a-e612-4fef-8c91-641870e3e578",
   "metadata": {},
   "source": [
    "## Presentación de los detalles del trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac52af-8475-4681-8c14-d1a4fc630ee2",
   "metadata": {},
   "source": [
    "Detalles del trabajo:\n",
    "* Todo el código parte de la idea de Andy Petrella: [Fundamentals-of-Data-Observability/oreilly-fodo-source-code](https://github.com/Fundamentals-of-Data-Observability/oreilly-fodo-source-code/blob/main/ch3/mp_3-20.py).\n",
    "* El Diagrama de Clases (UML) se encuentra en el siguiente enlace: [Diagrama de Clases *DOTKit Lib*](https://drive.google.com/file/d/1PUFU9CiwZVbsQGMjYE8sy5wnPkQDsrXV/view?usp=sharing).\n",
    "\n",
    "Pasos para desarrollar el proyecto:\n",
    "1. La idea inicial es formalizar un conjunto de clases extensibles que contengan el núcleo de las competencias en materia de observabilidad de datos respecto a las entidades del modelo *core* presentado posteriormente.\n",
    "2. El siguiente paso consistiría en aplicar el patrón de diseño de software *Decorador* (Decorator Software Design Pattern) a cada entidad, permitiendo al usuario embeber cada clase con la funcionalidad y la información necesarias.\n",
    "3. El tercer paso sería desarrollar uno o más conectores con diferentes bases de datos tanto relacionales como NoSQL (tengamos en cuenta que existen claras relaciones entre las distintas entidades, por lo que es necesario cuidar la redundancia y otros aspectos) para registrar los resultados de los procesos de observabilidad de datos.\n",
    "4. Existe una posibilidad más: Construir herramientas que adapten el uso de estas clases \"kernel\" al trabajo con distintas herramientas un poco más sofisticadas, como conexiones a BBDD (*mysql_connector*) o incluso herramientas no-code o generadoras de código.\n",
    "5. Por último, solo faltaría construir herramientas de aplicación de estas completencias a las técnicas básicas de tratamiento de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651dbf40-0295-4202-8050-58c07883dd14",
   "metadata": {},
   "source": [
    "## Otros trabajos similares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425a193-7802-421d-985a-8c59fea9d3c4",
   "metadata": {},
   "source": [
    "Search Command:\n",
    "\n",
    "***Title*[data observab\\*]**  ***and***\n",
    "\n",
    "***Abstract*[tool\\* *or* gadget *or* implement\\* *or* devic\\* *or* instrument\\* *or* machin\\*]** ***and***\n",
    "\n",
    "***Topic*[(program\\* *or* software) *and* (develop\\* *or* engin\\* *or* scienc\\*)]**\n",
    "\n",
    "WoS:\n",
    "* [Data Fusion of Observability Signals for Assisting Orchestration of Distributed Applications](https://www.webofscience.com/wos/alldb/full-record/WOS:000768127400001)\n",
    "* [The Rise of Data Observability: Architecting the Future of Data Trust](https://www.webofscience.com/wos/alldb/full-record/WOS:000810504300210)\n",
    "* [STOVEPipe: Observable Access Control of User Data for Untrusted Applications on Mobile Devices](https://www.webofscience.com/wos/alldb/full-record/WOS:000392947000097)\n",
    "* [Collaborative Research: Improving Spatial Observability of Dynamic Traffic Systems through Active Mobile Sensor Networks and Crowdsourced Data](https://www.webofscience.com/wos/alldb/full-record/GRANTS:13560455)\n",
    "* [Reinforcement Learning for Partially Observable Dynamic Processes: Adaptive Dynamic Programming Using Measured Output Data](https://www.webofscience.com/wos/alldb/full-record/WOS:000286388300002)\n",
    "* [Data-Driven Distributed Output Consensus Control for Partially Observable Multiagent Systems](https://www.webofscience.com/wos/alldb/full-record/WOS:000458655900011)\n",
    "\n",
    "SCOPUS:\n",
    "* [Marine Data Observability using KPIS: An MDSE Approach](https://www.scopus.com/record/display.uri?eid=2-s2.0-85182315765&origin=resultslist&sort=plf-f&src=s&sid=a083bf6eda73e5dd2d2b9429e4fc4245&sot=b&sdt=b&s=%28TITLE%28data+observab*%29+AND+ABS%28tool*+or+gadget+or+implement*+or+devic*+or+instrument*+or+machin*%29+AND+ALL%28%28program*+or+software%29+and+%28develop*+or+engin*+or+scienc*%29%29%29&sl=166&sessionSearchId=a083bf6eda73e5dd2d2b9429e4fc4245&relpos=3)\n",
    "* [A Method to Enhance Data Observability for Robot Calibration in Confined Space](https://www.scopus.com/record/display.uri?eid=2-s2.0-85174499204&origin=resultslist&sort=plf-f&src=s&sid=a083bf6eda73e5dd2d2b9429e4fc4245&sot=b&sdt=b&s=%28TITLE%28data+observab*%29+AND+ABS%28tool*+or+gadget+or+implement*+or+devic*+or+instrument*+or+machin*%29+AND+ALL%28%28program*+or+software%29+and+%28develop*+or+engin*+or+scienc*%29%29%29&sl=166&sessionSearchId=a083bf6eda73e5dd2d2b9429e4fc4245&relpos=4)\n",
    "* [Towards Lightweight Data Integration Using Multi-Workflow Provenance and Data Observability](https://www.scopus.com/record/display.uri?eid=2-s2.0-85174251062&origin=resultslist&sort=plf-f&src=s&sid=a083bf6eda73e5dd2d2b9429e4fc4245&sot=b&sdt=b&s=%28TITLE%28data+observab*%29+AND+ABS%28tool*+or+gadget+or+implement*+or+devic*+or+instrument*+or+machin*%29+AND+ALL%28%28program*+or+software%29+and+%28develop*+or+engin*+or+scienc*%29%29%29&sl=166&sessionSearchId=a083bf6eda73e5dd2d2b9429e4fc4245&relpos=5)\n",
    "* [Enhancing observability in distribution grids using smart meter data](https://www.scopus.com/record/display.uri?eid=2-s2.0-85037089687&origin=resultslist&sort=plf-f&src=s&sid=a083bf6eda73e5dd2d2b9429e4fc4245&sot=b&sdt=b&s=%28TITLE%28data+observab*%29+AND+ABS%28tool*+or+gadget+or+implement*+or+devic*+or+instrument*+or+machin*%29+AND+ALL%28%28program*+or+software%29+and+%28develop*+or+engin*+or+scienc*%29%29%29&sl=166&sessionSearchId=a083bf6eda73e5dd2d2b9429e4fc4245&relpos=14)\n",
    "* [Model-driven observability for big data storage](https://www.scopus.com/record/display.uri?eid=2-s2.0-84983314891&origin=resultslist&sort=plf-f&src=s&sid=a083bf6eda73e5dd2d2b9429e4fc4245&sot=b&sdt=b&s=%28TITLE%28data+observab*%29+AND+ABS%28tool*+or+gadget+or+implement*+or+devic*+or+instrument*+or+machin*%29+AND+ALL%28%28program*+or+software%29+and+%28develop*+or+engin*+or+scienc*%29%29%29&sl=166&sessionSearchId=a083bf6eda73e5dd2d2b9429e4fc4245&relpos=15)\n",
    "* []()\n",
    "* []()\n",
    "* []()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7479b4-cbc1-4cd8-bf64-1b6eb146093d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb69183f-c3d0-4338-ad8e-d6c05480ccf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248b01fa-c455-4823-ad62-2fd296e8de1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9228ef51-9700-419f-b162-79ffb845758f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef52e7c-8692-44b0-8641-f393cd56bcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import re\n",
    "from functools import reduce\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67292017-ea91-46c3-84b3-c6b60d36f2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b7438a-c864-4dfc-8a23-d2f5c8c8faa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6007038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ignac\\git\\jupyter\\dotkit\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ignac\\git\\jupyter\\dotkit\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 12.6/12.6 MB 71.5 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.2 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5660f9-32af-4d5a-9a3f-9e11dcc09c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138737c4-f57a-469c-bcaa-9947a2c7af61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1c464e-3c19-487a-818c-d01d34f059b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _default(self, obj):\n",
    "    return getattr(obj.__class__, \"to_json\", _default.default)(obj)\n",
    "\n",
    "_default.default = json.JSONEncoder().default\n",
    "json.JSONEncoder.default = _default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46650f-2481-45da-baf1-e310609b7f16",
   "metadata": {},
   "source": [
    "## Data Observability Core Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6bc059-b9e3-4d79-948c-a751eddea1c8",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"attachment:a0717a1a-4af6-4a4a-9150-65289649cece.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4edb7-99bf-4661-b751-55ca68013dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "043171a3-a9b1-409a-945f-3c2a867fe453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DOEntity(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_id(self) -> str:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def update_id(self) -> str:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def dump(self, file) -> None:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def to_json(self) -> dict:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def to_complete_json(self) -> dict:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def primary_key_gen(self) -> str:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b911191-917b-4aa3-ad75-cbefbfb6a536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DOBaseEntity(DOEntity, ABC):\n",
    "    id: str\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.id = self.get_id()\n",
    "    \n",
    "    def get_id(self) -> str:\n",
    "        return hashlib.md5(self.primary_key_gen().encode(\"utf-8\")).hexdigest()\n",
    "    \n",
    "    def update_id(self) -> str:\n",
    "        self.id = self.get_id()\n",
    "    \n",
    "    def dump(self, file) -> None:\n",
    "        json.dump(self, file)\n",
    "        file.write('\\r\\n')\n",
    "        \n",
    "    @abstractmethod\n",
    "    def to_json(self) -> dict:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def to_complete_json(self) -> dict:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def primary_key_gen(self) -> str:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a0fae0-a213-4604-a550-42b7ead7765e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DODecorator(DOEntity, ABC):\n",
    "    decorated_entity: DOEntity\n",
    "\n",
    "    def __init__(self, decorated_entity: DOEntity):\n",
    "        self.decorated_entity = decorated_entity\n",
    "    \n",
    "    def get_id(self) -> str:\n",
    "        return self.decorated_entity.get_id()\n",
    "        \n",
    "    def update_id(self) -> str:\n",
    "        return self.decorated_entity.update_id()\n",
    "    \n",
    "    def dump(self, file) -> None:\n",
    "        self.decorated_entity.dump(file)\n",
    "    \n",
    "    def to_json(self) -> dict:\n",
    "        return self.decorated_entity.to_json()\n",
    "    \n",
    "    def to_complete_json(self) -> dict:\n",
    "        return self.decorated_entity.to_complete_json()\n",
    "    \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.decorated_entity.primary_key_gen()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_fold_id(self) -> str:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_id(self) -> str:\n",
    "        return self.decorated_entity.get_id()\n",
    "    \n",
    "    def get_base_entity_type(self) -> type:\n",
    "        if isinstance(self.decorated_entity, DODecorator):\n",
    "            return self.decorated_entity.get_base_entity_type()\n",
    "        else:\n",
    "            return type(self.decorated_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c409bf-3a95-4371-b0c9-2796ae8c4577",
   "metadata": {},
   "source": [
    "### Physical Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf9fbf-bd87-4f04-8ace-867569f4af5f",
   "metadata": {},
   "source": [
    "#### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b73f718b-f924-44dd-9b02-15205c64b4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class User(DOBaseEntity):\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, name: str = None) -> None:\n",
    "        self.name = name if name is not None else User.fetch_local_user()\n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self) -> dict:\n",
    "        return {\"do_category\": \"User\", \"id\": self.id, \"name\": self.name}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"do_category\": \"User\", \"id\": self.id, \"name\": self.name}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.name\n",
    "\n",
    "    # Add static method to fetch the local user\n",
    "    @staticmethod\n",
    "    def fetch_local_user():\n",
    "        return os.getlogin()\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_name(self) -> str:\n",
    "        return self.name\n",
    "    \n",
    "    def set_name(self, name: str) -> None:\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff2fa1df-de07-49ce-af26-24442c372989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_User(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            user = User(\"igmarco\")\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        self.assertTrue(user.to_json() == {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'} and \n",
    "                          json.dumps(user) == '{\"do_category\": \"User\", \"id\": \"6591935a79dc4b03f8b58c5e79d01273\", \"name\": \"igmarco\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        self.assertEqual(user.to_complete_json(), {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        user = User(\"igmarco\")\n",
    "        user.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"do_category\": \"User\", \"id\": \"6591935a79dc4b03f8b58c5e79d01273\", \"name\": \"igmarco\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a566dbbc-f2f1-4689-96ce-d0dbfa0feead",
   "metadata": {},
   "source": [
    "#### Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85c8b02d-2de1-405f-94b5-75151b9e963b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Host(DOBaseEntity):\n",
    "    ip: str\n",
    "    port: int\n",
    "    purpose: str\n",
    "    name: str\n",
    "    \n",
    "    # Atributo estático que contiene los valores permitidos para \"purpose\"\n",
    "    allowed_purposes = set([\"Application\", \"Data\"])\n",
    "    \n",
    "    # Atributo estático que contiene la expresión regular para la dirección IP\n",
    "    ip_pattern = re.compile(r'^(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$')\n",
    "    \n",
    "    # Atributo estático que contiene la expresión regular para la dirección IP\n",
    "    port_pattern = re.compile(r'^(?:6553[0-5]|655[0-2][0-9]|65[0-4][0-9]{2}|6[0-4][0-9]{3}|[1-5][0-9]{4}|[1-9][0-9]{0,3}|0)$')\n",
    "\n",
    "    def __init__(self, ip: str = None, port: int = None, purpose: str = 'Application', name: str = None) -> None:\n",
    "            \n",
    "        # COMPROBACIONES\n",
    "        # Verifica si el formato de la dirección IP es válido\n",
    "        if ip is not None and not Host.ip_pattern.match(ip):\n",
    "            raise ValueError('El formato de la dirección IP no es válido')\n",
    "            \n",
    "        # Verifica si el puerto especificado es válido\n",
    "        if port is not None and not Host.port_pattern.match(str(port)):\n",
    "            raise ValueError('No se ha especificado un puerto válido')\n",
    "            \n",
    "        # Verifica si el propósito indicado es válido\n",
    "        if purpose not in Host.allowed_purposes:\n",
    "            raise ValueError(f'El propósito debe ser uno de los siguientes: {\", \".join(Host.allowed_purposes)}')\n",
    "            \n",
    "        # ASIGNACIONES\n",
    "        prov_name, self.ip = (None, ip) if ip is not None else Host.fetch_host_ip()\n",
    "        self.port = int(port) if port is not None else None\n",
    "        self.purpose = purpose\n",
    "        self.name = prov_name if name is None and prov_name is not None else name\n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self) -> dict:\n",
    "        return {\"do_category\": \"Host\", \"id\": self.id, \"ip\": self.ip, \"port\": self.port, \"purpose\": self.purpose, \"name\": self.name}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"do_category\": \"Host\", \"id\": self.id, \"ip\": self.ip, \"port\": self.port, \"purpose\": self.purpose, \"name\": self.name}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return str(self.port) + \":\" + self.ip\n",
    "\n",
    "    @staticmethod\n",
    "    def add_allowed_purpose(new_purpose) -> None:\n",
    "        Host.allowed_purposes.add(new_purpose)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_allowed_purpose(old_purpose) -> None:\n",
    "        Host.allowed_purposes.remove(old_purpose)\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_allowed_purpose(old_purpose, new_purpose) -> None:\n",
    "        Host.remove_allowed_purpose(old_purpose)\n",
    "        Host.add_allowed_purpose(new_purpose)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_allowed_purpose(old_purpose, new_purpose) -> list:\n",
    "        return Host.allowed_purposes\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_host_ip() -> (str, str):\n",
    "        # Obtener el nombre del host\n",
    "        host_name = socket.gethostname()\n",
    "\n",
    "        # Obtener la dirección IP del host\n",
    "        ip_address = socket.gethostbyname(host_name)\n",
    "        \n",
    "        return host_name, ip_address\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_ip(self) -> str:\n",
    "        return self.name\n",
    "    \n",
    "    def get_port(self) -> int:\n",
    "        return self.name\n",
    "    \n",
    "    def get_purpose(self) -> str:\n",
    "        return self.name\n",
    "    \n",
    "    def get_name(self) -> str:\n",
    "        return self.name\n",
    "    \n",
    "    def set_ip(self, ip: str) -> None:\n",
    "        # Verifica si el formato de la dirección IP es válido\n",
    "        if ip is not None and not Host.ip_pattern.match(ip):\n",
    "            raise ValueError('El formato de la dirección IP no es válido')\n",
    "            \n",
    "        self.ip = ip\n",
    "    \n",
    "    def set_port(self, port: int) -> None:\n",
    "        # Verifica si el puerto especificado es válido\n",
    "        if port is not None and not Host.port_pattern.match(str(port)):\n",
    "            raise ValueError('No se ha especificado un puerto válido')\n",
    "        self.port = port\n",
    "    \n",
    "    def set_purpose(self, purpose: str) -> None:\n",
    "        # Verifica si el propósito indicado es válido\n",
    "        if purpose not in Host.allowed_purposes:\n",
    "            raise ValueError(f'El propósito debe ser uno de los siguientes: {\", \".join(Host.allowed_purposes)}')\n",
    "        self.puspose = purpose\n",
    "    \n",
    "    def set_name(self, str) -> None:\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e99db1-8eb6-429b-93b4-5cda44056c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_Host(unittest.TestCase):\n",
    "    \n",
    "    def test_init1(self):\n",
    "        try:\n",
    "            host = Host(\"192.168.1.1\", 8888, \"Application\", \"Host 1\")\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_init2(self):\n",
    "        try:\n",
    "            host = Host()\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_init3(self):\n",
    "        with self.assertRaises(Exception):\n",
    "            host = Host(\"192.168.1.1\", 111111111, \"Application\", \"Host 1\")\n",
    "    \n",
    "    def test_init4(self):\n",
    "        with self.assertRaises(Exception):\n",
    "            host = Host(\"192.168.1.400\", 8888, \"Application\", \"Host 1\")\n",
    "    \n",
    "    def test_init5(self):\n",
    "        with self.assertRaises(Exception):\n",
    "            host = Host(\"192.168.1.1\", 8888, \"Otro tipo\", \"Host 1\")\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        host = Host(\"192.168.1.1\", 8888, \"Application\", \"Host 1\")\n",
    "        self.assertTrue(host.to_json() == {'do_category': 'Host', 'id': 'b90931d40587bd45d89897df6bede44f', 'ip': '192.168.1.1', 'port': 8888, 'purpose': 'Application', 'name': 'Host 1'} and \n",
    "                          json.dumps(host) == '{\"do_category\": \"Host\", \"id\": \"b90931d40587bd45d89897df6bede44f\", \"ip\": \"192.168.1.1\", \"port\": 8888, \"purpose\": \"Application\", \"name\": \"Host 1\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        host = Host(\"192.168.1.1\", 8888, \"Application\", \"Host 1\")\n",
    "        self.assertEqual(host.to_complete_json(), {'do_category': 'Host', 'id': 'b90931d40587bd45d89897df6bede44f', 'ip': '192.168.1.1', 'port': 8888, 'purpose': 'Application', 'name': 'Host 1'})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        host = Host(\"192.168.1.1\", 8888, \"Application\", \"Host 1\")\n",
    "        host.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"do_category\": \"Host\", \"id\": \"b90931d40587bd45d89897df6bede44f\", \"ip\": \"192.168.1.1\", \"port\": 8888, \"purpose\": \"Application\", \"name\": \"Host 1\"}\\n\\n')\n",
    "\n",
    "    def test_add_allowed_purpose(self):\n",
    "        try:\n",
    "            Host.add_allowed_purpose(\"Nuevo tipo 1\")\n",
    "            host = Host(\"192.168.1.1\", 8888, \"Nuevo tipo 1\", \"Host 1\")\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "            \n",
    "        self.assertEqual(host.to_json(), {'do_category': 'Host',\n",
    "                         'id': 'b90931d40587bd45d89897df6bede44f',\n",
    "                         'ip': '192.168.1.1',\n",
    "                         'port': 8888,\n",
    "                         'purpose': 'Nuevo tipo 1', \n",
    "                         'name': 'Host 1'})\n",
    "\n",
    "    def test_remove_allowed_purpose(self):\n",
    "        try:\n",
    "            Host.add_allowed_purpose(\"Nuevo tipo 1\")\n",
    "            Host.remove_allowed_purpose(\"Nuevo tipo 1\")\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            host = Host(\"192.168.1.1\", 8888, \"Nuevo tipo 1\", \"Host 1\")\n",
    "\n",
    "    def test_replace_allowed_purpose1(self):\n",
    "        try:\n",
    "            Host.add_allowed_purpose(\"Nuevo tipo 1\")\n",
    "            Host.replace_allowed_purpose(\"Nuevo tipo 1\", \"Nuevo tipo 2\")\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "            \n",
    "        with self.assertRaises(Exception):\n",
    "            host = Host(\"192.168.1.1\", 8888, \"Nuevo tipo 1\", \"Host 1\")\n",
    "\n",
    "    def test_replace_allowed_purpose2(self):\n",
    "        try:\n",
    "            Host.add_allowed_purpose(\"Nuevo tipo 1\")\n",
    "            Host.replace_allowed_purpose(\"Nuevo tipo 1\", \"Nuevo tipo 2\")\n",
    "            host = Host(\"192.168.1.1\", 8888, \"Nuevo tipo 2\", \"Host 1\")\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "            \n",
    "        self.assertEqual(host.to_json(), {'do_category': 'Host',\n",
    "                         'id': 'b90931d40587bd45d89897df6bede44f',\n",
    "                         'ip': '192.168.1.1',\n",
    "                         'port': 8888,\n",
    "                         'purpose': 'Nuevo tipo 2', \n",
    "                         'name': 'Host 1'})\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1354ff-ac18-4a0e-ad84-619ab9651b40",
   "metadata": {},
   "source": [
    "### Static Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e8aa8-37b2-4617-9bf9-dbe1e874d2e8",
   "metadata": {},
   "source": [
    "#### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3907e2b6-fbc9-4e74-ace6-0f759dc9dcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Application(DOBaseEntity):\n",
    "    name: str\n",
    "    owner: User\n",
    "\n",
    "    def __init__(self, name: str = None, owner: User = None) -> None:\n",
    "        self.name = name if name is not None else Application.fetch_file_name()\n",
    "        self.owner = owner\n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self) -> dict:\n",
    "        return {\"id\": self.id, \"name\": self.name, \"owner\": self.owner.id if self.owner is not None else None}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"name\": self.name, \"owner\": self.owner.to_complete_json() if self.owner is not None else None}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return ((self.owner.primary_key_gen() + \".\") if (self.owner is not None) else \"\") + self.name\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_file_name() -> str:\n",
    "        # application_name = os.path.basename(os.path.realpath(__file__))\n",
    "        application_name = os.path.basename(os.path.realpath(globals().get('__file__', '.')))\n",
    "        return application_name\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_owner(self) -> str:\n",
    "        return self.owner\n",
    "    \n",
    "    def get_user(self) -> User:\n",
    "        return self.user\n",
    "    \n",
    "    def set_owner(self, owner: str) -> None:\n",
    "        self.owner = owner\n",
    "    \n",
    "    def set_user(self, user: User) -> None:\n",
    "        self.user = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3fcd10-370b-4668-95d9-f1c598e1be04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_Application(unittest.TestCase):\n",
    "    \n",
    "    def test_init1(self):\n",
    "        try:\n",
    "            user = User(\"igmarco\")\n",
    "            app = Application(\"App\", user)\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_init2(self):\n",
    "        try:\n",
    "            app = Application()\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        self.assertTrue(app.to_json() == {'id': '3061a641cb7c5f8180c22fab74175d00', 'name': 'App', 'owner': '6591935a79dc4b03f8b58c5e79d01273'} and \n",
    "                          json.dumps(app) == '{\"id\": \"3061a641cb7c5f8180c22fab74175d00\", \"name\": \"App\", \"owner\": \"6591935a79dc4b03f8b58c5e79d01273\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        self.assertEqual(app.to_complete_json(), {'id': '3061a641cb7c5f8180c22fab74175d00', 'name': 'App', 'owner': {'do_category': 'User',\n",
    "                                                  'id': '6591935a79dc4b03f8b58c5e79d01273',\n",
    "                                                  'name': 'igmarco'}})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"3061a641cb7c5f8180c22fab74175d00\", \"name\": \"App\", \"owner\": \"6591935a79dc4b03f8b58c5e79d01273\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5fcf3-ae58-4c16-9aff-056feccf74f0",
   "metadata": {},
   "source": [
    "#### Application Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dacddaae-fc4c-4f38-bd37-ece67fa2270e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ApplicationRepository(DOBaseEntity):\n",
    "    location: str\n",
    "    application: Application\n",
    "    vcs: str\n",
    "    author: User\n",
    "    \n",
    "    # Atributo estático que contiene los valores permitidos para \"vcs\"\n",
    "    allowed_vcs = set([\"Git\", \"Local\"])\n",
    "    natively_allowed_vcs = set([\"Git\", \"Local\"])\n",
    "    default_vcs = \"Local\"\n",
    "\n",
    "    def __init__(self, application: Application = None, location: str = None, vcs: str = None, author: User = None) -> None:\n",
    "        self.application = application if application is not None else Application()\n",
    "            \n",
    "        # Verifica si el vcs indicado es válido\n",
    "        if vcs not in ApplicationRepository.allowed_vcs and vcs is not None:\n",
    "            raise ValueError(f'El sistema de control de versiones debe ser uno de los siguientes: {\", \".join(ApplicationRepository.allowed_vcs)}')\n",
    "            \n",
    "        self.vcs = vcs if vcs is not None else ApplicationRepository.default_vcs\n",
    "        \n",
    "        if location is None and self.vcs in ApplicationRepository.natively_allowed_vcs:\n",
    "            if self.vcs == \"Git\":\n",
    "                self.location, prov_author = ApplicationRepository.fetch_git_location()\n",
    "            if self.vcs == \"Local\":\n",
    "                self.location = ApplicationRepository.fetch_local_location()\n",
    "        else:\n",
    "            self.location = location\n",
    "        \n",
    "        if author is None and self.vcs in ApplicationRepository.natively_allowed_vcs:\n",
    "            if self.vcs == \"Git\":\n",
    "                prov_location, self.author = ApplicationRepository.fetch_git_location() if prov_author is None else (None, prov_author)\n",
    "            if self.vcs == \"Local\":\n",
    "                self.author = None\n",
    "        else:\n",
    "            self.author = author\n",
    "            \n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\"id\": self.id, \"location\": self.location, \"application\": self.application.id, \"author\": self.author.id if self.author is not None else None}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"location\": self.location, \"application\": self.application.to_complete_json(), \"author\": self.author.to_complete_json() if self.author is not None else None}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.application.primary_key_gen() + \".\" + self.vcs + ((\".\" + self.location) if (self.location is not None) else \"\")\n",
    "\n",
    "    # Add static method to fetch the git repo\n",
    "    @staticmethod\n",
    "    def fetch_git_location() -> (str, str):\n",
    "        code_repo = git.Repo(os.getcwd(), search_parent_directories=True).remote().url\n",
    "        # Separar la URL para extraer el propietario y el nombre del repositorio\n",
    "        # Suponiendo que la URL tiene el formato: https://github.com/propietario/repositorio.git\n",
    "        parts = code_repo.split('/')\n",
    "        owner = parts[-2]  # El penúltimo elemento es el nombre del propietario\n",
    "        author = User(owner)\n",
    "        return code_repo, author\n",
    "\n",
    "    # Add static method to fetch the local repo\n",
    "    @staticmethod\n",
    "    def fetch_local_location() -> str:\n",
    "        code_repo = os.path.realpath(globals().get('__file__', '.'))\n",
    "        return code_repo\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_location(self) -> str:\n",
    "        return self.location\n",
    "    \n",
    "    def get_application(self) -> Application:\n",
    "        return self.application\n",
    "    \n",
    "    def get_vcs(self) -> str:\n",
    "        return self.vcs\n",
    "    \n",
    "    def get_author(self) -> User:\n",
    "        return self.author\n",
    "    \n",
    "    def set_location(self, location: str) -> None:\n",
    "        self.location = location\n",
    "    \n",
    "    def set_application(self, application: Application) -> None:\n",
    "        self.application = application\n",
    "    \n",
    "    def set_vcs(self, vcs: str) -> None:\n",
    "        # Verifica si el vcs indicado es válido\n",
    "        if vcs not in ApplicationRepository.allowed_vcs and vcs is not None:\n",
    "            raise ValueError(f'El sistema de control de versiones debe ser uno de los siguientes: {\", \".join(ApplicationRepository.allowed_vcs)}')\n",
    "            \n",
    "        self.vcs = vcs\n",
    "    \n",
    "    def set_author(self, author: User) -> None:\n",
    "        self.author = author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "782be050-dcd5-4749-9970-5c3cfc79ab04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_ApplicationRepository(unittest.TestCase):\n",
    "    \n",
    "    def test_init1(self):\n",
    "        try:\n",
    "            user = User(\"igmarco\")\n",
    "            app = Application(\"App\", user)\n",
    "            app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_init2(self):\n",
    "        try:\n",
    "            app = ApplicationRepository()\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        self.assertTrue(app_repo.to_json() == {'id': '2a4cefc59444a3dac2df584d70730523',\n",
    "                                                 'location': 'igmarco/DOTKit.git',\n",
    "                                                 'application': '3061a641cb7c5f8180c22fab74175d00',\n",
    "                                                 'author': '6591935a79dc4b03f8b58c5e79d01273'} and \n",
    "                          json.dumps(app_repo) == '{\"id\": \"2a4cefc59444a3dac2df584d70730523\", \"location\": \"igmarco/DOTKit.git\", \"application\": \"3061a641cb7c5f8180c22fab74175d00\", \"author\": \"6591935a79dc4b03f8b58c5e79d01273\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        self.assertEqual(app_repo.to_complete_json(), {'id': '2a4cefc59444a3dac2df584d70730523',\n",
    "                                                 'location': 'igmarco/DOTKit.git',\n",
    "                                                 'application': {'id': '3061a641cb7c5f8180c22fab74175d00',\n",
    "                                                  'name': 'App',\n",
    "                                                  'owner': {'do_category': 'User',\n",
    "                                                              'id': '6591935a79dc4b03f8b58c5e79d01273',\n",
    "                                                              'name': 'igmarco'}},\n",
    "                                                    'author': {'do_category': 'User',\n",
    "                                                              'id': '6591935a79dc4b03f8b58c5e79d01273',\n",
    "                                                              'name': 'igmarco'}})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_repo.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"2a4cefc59444a3dac2df584d70730523\", \"location\": \"igmarco/DOTKit.git\", \"application\": \"3061a641cb7c5f8180c22fab74175d00\", \"author\": \"6591935a79dc4b03f8b58c5e79d01273\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d0ebc-39ea-49e1-a613-b4728bd48b45",
   "metadata": {},
   "source": [
    "#### Application Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6e39a49-7f9c-4fa2-9a5b-720d49d1c8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ApplicationVersion(DOBaseEntity):\n",
    "    version: str\n",
    "    author: User\n",
    "    application_repo: ApplicationRepository\n",
    "    \n",
    "    # Atributo estático que contiene la expresión regular para la versión de la aplicación\n",
    "    version_pattern = re.compile(r'.*')\n",
    "\n",
    "    def __init__(self, application_repo: ApplicationRepository, version: str = None, author: User = None) -> None:\n",
    "        \n",
    "        # COMPROBACIONES\n",
    "        # Verifica si el formato de la versión es válido\n",
    "        if version is not None and not ApplicationVersion.version_pattern.match(version):\n",
    "            raise ValueError('El formato de la versión no es válido')\n",
    "        \n",
    "        self.application_repo = application_repo\n",
    "        \n",
    "        if version is None and application_repo.vcs in ApplicationRepository.natively_allowed_vcs:\n",
    "            if application_repo.vcs == \"Git\":\n",
    "                self.version = ApplicationVersion.fetch_git_version()\n",
    "            if application_repo.vcs ==  \"Local\":\n",
    "                self.version = None\n",
    "        else:\n",
    "            self.version = version\n",
    "        \n",
    "        if author is None and application_repo.vcs in ApplicationRepository.natively_allowed_vcs:\n",
    "            if application_repo.vcs ==  \"Git\":\n",
    "                self.author = User(ApplicationVersion.fetch_git_commit_author())\n",
    "            if application_repo.vcs ==  \"Local\":\n",
    "                self.author = None\n",
    "        else:\n",
    "            self.author = author\n",
    "            \n",
    "        super().__init__()\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return ((self.version + \".\") if self.version is not None else \"\") + ((self.author.primary_key_gen() + \".\") if self.author is not None else \"\") + self.application_repo.primary_key_gen()\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\"id\": self.id, \"version\": self.version, \"author\": self.author.id if self.author is not None else None,\n",
    "                \"application_repository\": self.application_repo.id}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"version\": self.version, \"author\": self.author.to_complete_json() if self.author is not None else None,\n",
    "                \"application_repository\": self.application_repo.to_complete_json()}\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_git_version():\n",
    "        import git\n",
    "        repo = git.Repo(os.getcwd(), search_parent_directories=True)\n",
    "        commit = repo.head.commit\n",
    "        code_version = commit.hexsha\n",
    "        return code_version\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_git_commit_author():\n",
    "        import git\n",
    "        repo = git.Repo(os.getcwd(), search_parent_directories=True)\n",
    "        commit = repo.head.commit\n",
    "        code_author = commit.author.name\n",
    "        return code_author\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_version(self) -> str:\n",
    "        return self.version\n",
    "    \n",
    "    def get_author(self) -> User:\n",
    "        return self.author\n",
    "    \n",
    "    def get_application_repo(self) -> ApplicationRepository:\n",
    "        return self.application_repo\n",
    "    \n",
    "    def set_version(self, version: str) -> None:\n",
    "        # Verifica si el formato de la versión es válido\n",
    "        if version is not None and not ApplicationVersion.version_pattern.match(version):\n",
    "            raise ValueError('El formato de la versión no es válido')\n",
    "            \n",
    "        self.version = version\n",
    "    \n",
    "    def set_author(self, author: User) -> None:\n",
    "        self.author = author\n",
    "    \n",
    "    def set_application_repo(self, application_repo: ApplicationRepository) -> None:\n",
    "        self.application_repo = application_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d7b1e2e-3d0d-4b82-a08f-439a2a910a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_ApplicationVersion(unittest.TestCase):\n",
    "    \n",
    "    def test_init1(self):\n",
    "        try:\n",
    "            user = User(\"igmarco\")\n",
    "            app = Application(\"App\", user)\n",
    "            app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "            app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_init2(self):\n",
    "        try:\n",
    "            app_version = ApplicationVersion(ApplicationRepository())\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        self.assertTrue(app_version.to_json() == {'id': '397343e65b1cd68a37d18e09c203b5bf', 'version': '1.0', 'author': '6591935a79dc4b03f8b58c5e79d01273', 'application_repository': '2a4cefc59444a3dac2df584d70730523'} and \n",
    "                          json.dumps(app_version) == '{\"id\": \"397343e65b1cd68a37d18e09c203b5bf\", \"version\": \"1.0\", \"author\": \"6591935a79dc4b03f8b58c5e79d01273\", \"application_repository\": \"2a4cefc59444a3dac2df584d70730523\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        self.assertEqual(app_version.to_complete_json(), {'id': '397343e65b1cd68a37d18e09c203b5bf', 'version': '1.0', 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'application_repository': {'id': '2a4cefc59444a3dac2df584d70730523', 'location': 'igmarco/DOTKit.git', 'application': {'id': '3061a641cb7c5f8180c22fab74175d00', 'name': 'App', 'owner': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}, 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_version.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"397343e65b1cd68a37d18e09c203b5bf\", \"version\": \"1.0\", \"author\": \"6591935a79dc4b03f8b58c5e79d01273\", \"application_repository\": \"2a4cefc59444a3dac2df584d70730523\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce87a9-1cb8-423e-ab59-acaaf36f777e",
   "metadata": {},
   "source": [
    "#### Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "237d3c86-07a2-4864-adc3-c6cf1ce14061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSource(DOBaseEntity):\n",
    "    location: str\n",
    "    format: str\n",
    "    type: str\n",
    "\n",
    "    def __init__(self, location: str, format: str = None, type: str = \"File\") -> None:\n",
    "        self.location = location\n",
    "        self.format = format\n",
    "        self.type = type\n",
    "            \n",
    "        super().__init__()\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.location + \".\" + self.format\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\"id\": self.id, \"location\": self.location, \"format\": self.format, \"type\": self.type}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"location\": self.location, \"format\": self.format, \"type\": self.type}\n",
    "    \n",
    "    def exists(self):\n",
    "        # Obtener la ruta del directorio actual\n",
    "        current_directory = os.getcwd()\n",
    "\n",
    "        # Construir la ruta al archivo \"data.csv\"\n",
    "        data_source_path = os.path.join(current_directory, self.location + \".\" + self.format)\n",
    "        return os.path.exists(data_source_path)\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_location(self) -> str:\n",
    "        return self.version\n",
    "    \n",
    "    def get_format(self) -> str:\n",
    "        return self.format\n",
    "    \n",
    "    def get_type(self) -> str:\n",
    "        return self.type\n",
    "    \n",
    "    def set_location(self, location: str) -> None:\n",
    "        self.location = location\n",
    "    \n",
    "    def set_format(self, format: str) -> None:\n",
    "        self.format = format\n",
    "    \n",
    "    def set_type(self, type: str) -> None:\n",
    "        self.type = type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "272c9349-1558-4a02-8825-bf2d74b41d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_DataSource(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            ds = DataSource('DOFile', 'txt')\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        ds = DataSource('DOFile', 'txt')\n",
    "        self.assertTrue(ds.to_json() == {'id': '662e63715730d6ea700c9462ef71f0a5', 'location': 'DOFile', 'format': 'txt', 'type': 'File'} and \n",
    "                          json.dumps(ds) == '{\"id\": \"662e63715730d6ea700c9462ef71f0a5\", \"location\": \"DOFile\", \"format\": \"txt\", \"type\": \"File\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        ds = DataSource('DOFile', 'txt')\n",
    "        self.assertEqual(ds.to_complete_json(), {'id': '662e63715730d6ea700c9462ef71f0a5', 'location': 'DOFile', 'format': 'txt', 'type': 'File'})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        ds = DataSource('DOFile', 'txt')\n",
    "        ds.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"662e63715730d6ea700c9462ef71f0a5\", \"location\": \"DOFile\", \"format\": \"txt\", \"type\": \"File\"}\\n\\n')\n",
    "        \n",
    "    def test_exists1(self):\n",
    "        with open(\"file.txt\", \"w\") as file:\n",
    "            pass\n",
    "        \n",
    "        ds = DataSource('file', 'txt')\n",
    "        self.assertTrue(ds.exists())\n",
    "        \n",
    "        os.remove('file.txt')\n",
    "        \n",
    "    def test_exists2(self):\n",
    "        ds = DataSource('//////', 'txt')\n",
    "        self.assertFalse(ds.exists())\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed70475-0e6e-4725-9bfd-937f64702caf",
   "metadata": {},
   "source": [
    "#### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "286ba8d8-cfb0-4664-83c3-af5be2e0c9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Schema(DOBaseEntity):\n",
    "    fields: list[tuple[str, str]]\n",
    "    data_source: DataSource\n",
    "\n",
    "    def __init__(self, fields: list[tuple[str, str]], data_source: DataSource) -> None:\n",
    "        self.fields = fields\n",
    "        self.data_source = data_source\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self):\n",
    "        jfields = reduce(lambda x, y: dict(**x, **y), map(lambda f: {f[0]: f[1]}, self.fields))\n",
    "        return {\"id\": self.id, \"fields\": jfields, \"data_source\": self.data_source.id}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        jfields = reduce(lambda x, y: dict(**x, **y), map(lambda f: {f[0]: f[1]}, self.fields))\n",
    "        return {\"id\": self.id, \"fields\": jfields, \"data_source\": self.data_source.to_complete_json()}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        linearized_fields = self.linearize()\n",
    "        return self.data_source.primary_key_gen() + \".\" + linearized_fields\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_fields_from_dataframe(df: pd.DataFrame): # Falta test unitario\n",
    "        fs = list(zip(df.columns.values.tolist(), map(lambda x: str(x), df.dtypes.values.tolist())))\n",
    "        return fs\n",
    "\n",
    "    def linearize(self): # Falta test unitario\n",
    "        return \",\".join(list(map(lambda x: x[0] + \"-\" + x[1], sorted(self.fields))))\n",
    "        return fs\n",
    "    \n",
    "    def copy(self): # Falta test unitario\n",
    "        return Schema(self.fields.copy(), self.data_source)\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_fields(self) -> str:\n",
    "        return self.fields\n",
    "    \n",
    "    def get_data_source(self) -> str:\n",
    "        return self.data_source\n",
    "    \n",
    "    def set_fields(self, fields: list[tuple[str, str]]) -> None:\n",
    "        self.fields = fields\n",
    "    \n",
    "    def set_data_source(self, data_source: DataSource) -> None:\n",
    "        self.data_source = data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b9d45a5-c89e-4a86-b444-97c8b09d3a39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir los datos\n",
    "data = [\n",
    "    {\"in\": 1, \"out\": 2},\n",
    "    {\"in\": 2, \"out\": 4},\n",
    "    {\"in\": 3, \"out\": 6},\n",
    "    {\"in\": 4, \"out\": 8},\n",
    "    {\"in\": 5, \"out\": 10}\n",
    "]\n",
    "\n",
    "# Nombre del archivo CSV\n",
    "csv_name = \"double.csv\"\n",
    "\n",
    "# Escribir los datos en el archivo CSV\n",
    "with open(csv_name, mode='w', newline='') as file:\n",
    "    # Definir el encabezado del archivo CSV\n",
    "    fields = ['in', 'out']\n",
    "    writer = csv.DictWriter(file, fieldnames=fields)\n",
    "\n",
    "    # Escribir el encabezado\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Escribir los datos\n",
    "    for datum in data:\n",
    "        writer.writerow(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "091d64bb-fc5b-476e-88d8-ad0b61b22aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_Schema(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            ds = DataSource(\"doble\", 'csv')\n",
    "            schema = Schema([(\"in\",\"double_in\"),(\"out\",\"double_out\")], ds)\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        ds = DataSource(\"doble\", 'csv')\n",
    "        schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], ds)\n",
    "        self.assertTrue(schema.to_json() == {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': '0157a60140d093df8270457e485049da'} and \n",
    "                          json.dumps(schema) == '{\"id\": \"7cb6bb065abd790fda4b7e922857d78b\", \"fields\": {\"in\": \"int64\", \"out\": \"int64\"}, \"data_source\": \"0157a60140d093df8270457e485049da\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        \n",
    "        ds = DataSource(\"doble\", 'csv')\n",
    "        schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], ds)\n",
    "        self.assertEqual(schema.to_complete_json(), {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        \n",
    "        ds = DataSource(\"doble\", 'csv')\n",
    "        schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], ds)\n",
    "        schema.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"7cb6bb065abd790fda4b7e922857d78b\", \"fields\": {\"in\": \"int64\", \"out\": \"int64\"}, \"data_source\": \"0157a60140d093df8270457e485049da\"}\\n\\n')\n",
    "\n",
    "    def test_extract_fields_from_dataframe(self):\n",
    "        df = pd.read_csv(\"double.csv\", header=0)\n",
    "        self.assertEqual(Schema.extract_fields_from_dataframe(df), [('in', 'int64'), ('out', 'int64')])\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c9131-c822-4570-9ce3-fe5cdb7a3a8d",
   "metadata": {},
   "source": [
    "#### Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96ef02a0-ac45-4446-b008-e049e3c31807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lineage(DOBaseEntity):\n",
    "    output_schema: Schema\n",
    "    # input_schemas: list[tuple[Schema, dict]]\n",
    "    input_schemas_mapping: list[tuple[Schema, dict]]\n",
    "\n",
    "    def __init__(self, output_schema: Schema, input_schemas_mapping: list[tuple[Schema, dict]]) -> None:\n",
    "        self.output_schema = output_schema\n",
    "        self.input_schemas_mapping = input_schemas_mapping # if input_schemas_mapping is not None else []\n",
    "        self.id = hashlib.md5(\",\".join([self.output_schema.id]).encode(\"utf-8\") + self.linearize().encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\"id\": self.id, \"output_schema\": self.output_schema.id, \"input_schemas_mapping\": self.to_json_input_schemas_mapping()}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"output_schema\": self.output_schema.id, \"input_schemas_mapping\": self.to_complete_json_input_schemas_mapping()}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.output_schema.primary_key_gen() + self.linearize()\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_direct_mapping(output_schema: Schema, input_schemas: list[Schema]) -> dict:\n",
    "        input_schemas = input_schemas\n",
    "        input_schemas_mapping = []\n",
    "        output_schema_field_names = [f[0] for f in output_schema.fields]\n",
    "        for schema in input_schemas:\n",
    "            mapping = {}\n",
    "            for field in schema.fields:\n",
    "                if field[0] in output_schema_field_names:\n",
    "                    mapping[field[0]] = [field[0]]\n",
    "            if len(mapping):\n",
    "                input_schemas_mapping.append((schema, mapping))\n",
    "        return input_schemas_mapping\n",
    "\n",
    "    def linearize(self):\n",
    "        linearized = \"\"\n",
    "        for schema in self.input_schemas_mapping:\n",
    "            for k in schema[1]:\n",
    "                linearized += (k + \":\")\n",
    "                linearized += (\"-\".join(schema[1][k]) + \",\")\n",
    "        linearized = linearized[:-1]\n",
    "        return linearized\n",
    "    \n",
    "    def to_json_input_schemas_mapping(self):\n",
    "        jinput_schemas_mapping = dict()\n",
    "        for schema_mapping in self.input_schemas_mapping:\n",
    "            c_schema = schema_mapping[0].copy()\n",
    "            while c_schema.id in jinput_schemas_mapping:\n",
    "                schema_splitted = c_schema.id.split('_')\n",
    "                if len(schema_splitted) == 1:\n",
    "                    c_schema.id = schema_splitted[0] + '_2'\n",
    "                else:\n",
    "                    c_schema.id = schema_splitted[0] + '_' + str(int(schema_splitted[1]) + 1)\n",
    "            jinput_schemas_mapping[c_schema.id] = schema_mapping[1]\n",
    "            \n",
    "        return jinput_schemas_mapping\n",
    "    \n",
    "    def to_complete_json_input_schemas_mapping(self):\n",
    "        jinput_schemas_mapping = dict()\n",
    "        for schema_mapping in self.input_schemas_mapping:\n",
    "            c_schema = schema_mapping[0].copy()\n",
    "            while c_schema.id in jinput_schemas_mapping:\n",
    "                schema_splitted = c_schema.id.split('_')\n",
    "                if len(schema_splitted) == 1:\n",
    "                    c_schema.id = schema_splitted[0] + '_2'\n",
    "                else:\n",
    "                    c_schema.id = schema_splitted[0] + '_' + str(int(schema_splitted[1]) + 1)\n",
    "                    \n",
    "            jinput_schemas_mapping[c_schema.id] = [schema_mapping[1], schema_mapping[0].to_complete_json()]\n",
    "            \n",
    "        return jinput_schemas_mapping\n",
    "    \n",
    "    def get_schema_ids_list(self) -> list: # Falta test unitario\n",
    "        schema_ids_set = set([self.output_schema.id])\n",
    "        for schema_map in self.input_schemas_mapping:\n",
    "            schema_ids_set = schema_ids_set | set([schema_map[0].id])\n",
    "        return schema_ids_set\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_output_schema(self) -> Schema:\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_input_schema_mapping(self) -> list[tuple[Schema, dict]]:\n",
    "        return self.input_schema_mapping\n",
    "    \n",
    "    def set_output_schema(self, output_schema: Schema) -> None:\n",
    "        self.output_schema = output_schema\n",
    "    \n",
    "    def set_input_schema_mapping(self, input_schema_mapping: list[tuple[Schema, dict]]) -> None:\n",
    "        self.input_schema_mapping = input_schema_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8c8c09c-153d-4dbd-9050-56ee0d85d52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_Lineage(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            i_ds = DataSource(\"doble\", 'csv')\n",
    "            o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "            i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "            o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "            lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        self.assertTrue(lineage.to_json() == {'id': '6c6b2412a3f1dafa2deb6d48c042d819', 'output_schema': 'd25d63ce93fc6d20dbe3bc78ee3c9253', 'input_schemas_mapping': {'7cb6bb065abd790fda4b7e922857d78b': {'in': ['in'], 'out': ['out']}, '7cb6bb065abd790fda4b7e922857d78b_2': {'in': ['in'], 'out': ['out']}}} and \n",
    "                          json.dumps(lineage) == '{\"id\": \"6c6b2412a3f1dafa2deb6d48c042d819\", \"output_schema\": \"d25d63ce93fc6d20dbe3bc78ee3c9253\", \"input_schemas_mapping\": {\"7cb6bb065abd790fda4b7e922857d78b\": {\"in\": [\"in\"], \"out\": [\"out\"]}, \"7cb6bb065abd790fda4b7e922857d78b_2\": {\"in\": [\"in\"], \"out\": [\"out\"]}}}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        \n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        self.assertEqual(lineage.to_complete_json(), {'id': '6c6b2412a3f1dafa2deb6d48c042d819', 'output_schema': 'd25d63ce93fc6d20dbe3bc78ee3c9253', 'input_schemas_mapping': {'7cb6bb065abd790fda4b7e922857d78b': [{'in': ['in'], 'out': ['out']}, {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}}], '7cb6bb065abd790fda4b7e922857d78b_2': [{'in': ['in'], 'out': ['out']}, {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}}]}})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        \n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        lineage.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"6c6b2412a3f1dafa2deb6d48c042d819\", \"output_schema\": \"d25d63ce93fc6d20dbe3bc78ee3c9253\", \"input_schemas_mapping\": {\"7cb6bb065abd790fda4b7e922857d78b\": {\"in\": [\"in\"], \"out\": [\"out\"]}, \"7cb6bb065abd790fda4b7e922857d78b_2\": {\"in\": [\"in\"], \"out\": [\"out\"]}}}\\n\\n')\n",
    "\n",
    "    def test_get_schema_ids_list(self):\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        \n",
    "        self.assertEqual(lineage.get_schema_ids_list(), set(['d25d63ce93fc6d20dbe3bc78ee3c9253', '7cb6bb065abd790fda4b7e922857d78b']))\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd75e6-d850-4c49-8b25-fcd9c188019a",
   "metadata": {},
   "source": [
    "### Dynamic Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6e9a3-a4b0-4550-a3ae-0995fcd32aaf",
   "metadata": {},
   "source": [
    "#### Application Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7242d7bc-eb98-48cd-8538-53d8e4215917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ApplicationExecution(DOBaseEntity):\n",
    "    application_version: ApplicationVersion\n",
    "    user: User\n",
    "    start_time: str\n",
    "\n",
    "    def __init__(self, application_version: ApplicationVersion, user: User) -> None:\n",
    "        self.application_version = application_version\n",
    "        self.user = user if user is not None else User()\n",
    "        self.start_time = datetime.datetime.now().isoformat()\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\"id\": self.id, \"application_version\": self.application_version.id, \"user\": self.user.id,\n",
    "                \"start_time\": self.start_time}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"application_version\": self.application_version.to_complete_json(), \"user\": self.user.to_complete_json(),\n",
    "                \"start_time\": self.start_time}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.application_version.primary_key_gen() + \".\" + self.user.primary_key_gen() + \".\" + self.start_time\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_application_version(self) -> ApplicationVersion:\n",
    "        return self.application_version\n",
    "    \n",
    "    def get_user(self) -> User:\n",
    "        return self.user\n",
    "    \n",
    "    def get_start_time(self) -> str:\n",
    "        return self.start_time\n",
    "    \n",
    "    def set_application_version(self, application_version: ApplicationVersion) -> None:\n",
    "        self.application_version = application_version\n",
    "    \n",
    "    def set_user(self, user: User) -> None:\n",
    "        self.user = user\n",
    "    \n",
    "    def set_start_time(self, start_time: str) -> None:\n",
    "        self.start_time = start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3affd314-60c8-444e-8a1b-2589048aed47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_ApplicationExecution(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            user = User(\"igmarco\")\n",
    "            app = Application(\"App\", user)\n",
    "            app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "            app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "            app_exe = ApplicationExecution(app_version, user)\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        self.assertTrue(app_exe.to_json() == {'id': app_exe.id, 'application_version': '397343e65b1cd68a37d18e09c203b5bf', 'user': '6591935a79dc4b03f8b58c5e79d01273', 'start_time': app_exe.start_time} and \n",
    "                          json.dumps(app_exe) == '{\"id\": \"' + app_exe.id + '\", \"application_version\": \"397343e65b1cd68a37d18e09c203b5bf\", \"user\": \"6591935a79dc4b03f8b58c5e79d01273\", \"start_time\": \"' + app_exe.start_time + '\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        self.assertEqual(app_exe.to_complete_json(), {'id': app_exe.id, 'application_version': {'id': '397343e65b1cd68a37d18e09c203b5bf', 'version': '1.0', 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'application_repository': {'id': '2a4cefc59444a3dac2df584d70730523', 'location': 'igmarco/DOTKit.git', 'application': {'id': '3061a641cb7c5f8180c22fab74175d00', 'name': 'App', 'owner': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}, 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}}, 'user': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'start_time': app_exe.start_time})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        app_exe.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"' + app_exe.id + '\", \"application_version\": \"397343e65b1cd68a37d18e09c203b5bf\", \"user\": \"6591935a79dc4b03f8b58c5e79d01273\", \"start_time\": \"' + app_exe.start_time + '\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b552719-8150-44f6-abe9-51d4e29024d0",
   "metadata": {},
   "source": [
    "#### Lineage Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6198ff19-b68c-480f-a1f7-c4ec30371340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LineageExecution(DOBaseEntity):\n",
    "    lineage: Lineage\n",
    "    application_execution: ApplicationExecution\n",
    "    start_time: str\n",
    "\n",
    "    def __init__(self, lineage: Lineage, application_execution: ApplicationExecution) -> None:\n",
    "        self.lineage = lineage\n",
    "        self.application_execution = application_execution\n",
    "        self.start_time = datetime.datetime.now().isoformat()\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\"id\": self.id, \"lineage\": self.lineage.id, \"application_execution\": self.application_execution.id,\n",
    "                \"start_time\": self.start_time}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        return {\"id\": self.id, \"lineage\": self.lineage.to_complete_json(), \"application_execution\": self.application_execution.to_complete_json(),\n",
    "                \"start_time\": self.start_time}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.lineage.primary_key_gen() + \".\" + self.application_execution.primary_key_gen() + \".\" + self.start_time\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_lineage(self) -> Lineage:\n",
    "        return self.lineage\n",
    "    \n",
    "    def get_application_execution(self) -> ApplicationExecution:\n",
    "        return self.application_execution\n",
    "    \n",
    "    def get_start_time(self) -> str:\n",
    "        return self.start_time\n",
    "    \n",
    "    def set_lineage(self, lineage: Lineage) -> None:\n",
    "        self.lineage = lineage\n",
    "    \n",
    "    def set_application_execution(self, application_execution: ApplicationExecution) -> None:\n",
    "        self.application_execution = application_execution\n",
    "    \n",
    "    def set_start_time(self, start_time: str) -> None:\n",
    "        self.start_time = start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0affeae2-0086-4136-b246-6b0e585d07f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_LineageExecution(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            i_ds = DataSource(\"doble\", 'csv')\n",
    "            o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "            i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "            o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "            lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "            user = User(\"igmarco\")\n",
    "            app = Application(\"App\", user)\n",
    "            app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "            app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "            app_exe = ApplicationExecution(app_version, user)\n",
    "            lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        self.assertTrue(lineage_exe.to_json() == {'id': lineage_exe.id, 'lineage': '6c6b2412a3f1dafa2deb6d48c042d819', 'application_execution': app_exe.id, 'start_time': lineage_exe.start_time} and \n",
    "                          json.dumps(lineage_exe) == '{\"id\": \"' + lineage_exe.id + '\", \"lineage\": \"6c6b2412a3f1dafa2deb6d48c042d819\", \"application_execution\": \"' + app_exe.id + '\", \"start_time\": \"' + lineage_exe.start_time + '\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        self.assertEqual(lineage_exe.to_complete_json(), {'id': lineage_exe.id, 'lineage': {'id': '6c6b2412a3f1dafa2deb6d48c042d819', 'output_schema': 'd25d63ce93fc6d20dbe3bc78ee3c9253', 'input_schemas_mapping': {'7cb6bb065abd790fda4b7e922857d78b': [{'in': ['in'], 'out': ['out']}, {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}}], '7cb6bb065abd790fda4b7e922857d78b_2': [{'in': ['in'], 'out': ['out']}, {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}}]}}, 'application_execution': {'id': app_exe.id, 'application_version': {'id': '397343e65b1cd68a37d18e09c203b5bf', 'version': '1.0', 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'application_repository': {'id': '2a4cefc59444a3dac2df584d70730523', 'location': 'igmarco/DOTKit.git', 'application': {'id': '3061a641cb7c5f8180c22fab74175d00', 'name': 'App', 'owner': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}, 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}}, 'user': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'start_time': app_exe.start_time}, 'start_time': lineage_exe.start_time})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        lineage_exe.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"' + lineage_exe.id + '\", \"lineage\": \"6c6b2412a3f1dafa2deb6d48c042d819\", \"application_execution\": \"' + app_exe.id + '\", \"start_time\": \"' + lineage_exe.start_time + '\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c87166-f132-4778-a9a9-60d99947b6a7",
   "metadata": {},
   "source": [
    "#### Data Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0beb4c29-3fd2-4dc7-bec9-a24d5ac97745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataMetrics(DOBaseEntity):\n",
    "    schema: Schema # output_schema o alguno de los del input_schemas_mapping\n",
    "    lineage_execution: LineageExecution\n",
    "    metrics: list[tuple[str, float]]\n",
    "\n",
    "    def __init__(self, schema: Schema, lineage_execution: LineageExecution, metrics: list[tuple[str, float]]) -> None:\n",
    "        self.metrics = metrics\n",
    "        self.schema = schema\n",
    "        self.lineage_execution = lineage_execution\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    def to_json(self):\n",
    "        from functools import reduce\n",
    "        jfields = reduce(lambda x, y: dict(**x, **y), map(lambda f: {f[0]: f[1]}, self.metrics))\n",
    "        return {\"id\": self.id, \"metrics\": jfields, \"schema\": self.schema.id, \"lineage_execution\": self.lineage_execution.id}\n",
    "\n",
    "    def to_complete_json(self):\n",
    "        jfields = reduce(lambda x, y: dict(**x, **y), map(lambda f: {f[0]: f[1]}, self.metrics))\n",
    "        return {\"id\": self.id, \"metrics\": jfields, \"schema\": self.schema.to_complete_json(), \"lineage_execution\": self.lineage_execution.to_complete_json()}\n",
    "        \n",
    "    def primary_key_gen(self) -> str:\n",
    "        return self.schema.primary_key_gen() + \".\" + self.lineage_execution.primary_key_gen()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_metrics_from_dataframe(df: pd.DataFrame): # Falta test unitario\n",
    "        d = df.describe(include='all')\n",
    "        metrics = {}\n",
    "        for field in d.columns[1:]:\n",
    "            msd = dict(filter(lambda x: isinstance(x[1], numbers.Number) and math.isnan(x[1]) is False,\n",
    "                              map(lambda x: (field + \".\" + x[0], x[1]), d[field].to_dict().items())))\n",
    "            metrics.update(msd)\n",
    "        return list(metrics.items())\n",
    "    \n",
    "    def validate_schema_in_lineage(self):\n",
    "        return self.schema.id in self.lineage_execution.lineage.get_schema_ids_list()\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_schema(self) -> Schema:\n",
    "        return self.schema\n",
    "    \n",
    "    def get_lineage_execution(self) -> LineageExecution:\n",
    "        return self.lineage_execution\n",
    "    \n",
    "    def get_metrics(self) -> list[tuple[str, float]]:\n",
    "        return self.metrics\n",
    "    \n",
    "    def set_schema(self, schema: Schema) -> None:\n",
    "        self.schema = schema\n",
    "    \n",
    "    def set_lineage_execution(self, lineage_execution: LineageExecution) -> None:\n",
    "        self.lineage_execution = lineage_execution\n",
    "    \n",
    "    def set_metrics(self, metrics: list[tuple[str, float]]) -> None:\n",
    "        self.metrics = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85e0af53-7b83-4788-b387-e7944f9446a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test_DataMetrics(unittest.TestCase):\n",
    "    \n",
    "    def test_init(self):\n",
    "        try:\n",
    "            i_ds = DataSource(\"doble\", 'csv')\n",
    "            o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "            i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "            o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "            lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "            user = User(\"igmarco\")\n",
    "            app = Application(\"App\", user)\n",
    "            app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "            app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "            app_exe = ApplicationExecution(app_version, user)\n",
    "            lineage_exe = LineageExecution(lineage, app_exe)\n",
    "            dm = DataMetrics(o_schema, lineage_exe, [(\"mean\", 5.42), (\"std\", 0.67)])\n",
    "        except Exception as e:\n",
    "            self.fail(\"Se produjo una excepción inesperada: \" + str(e))\n",
    "    \n",
    "    def test_to_json(self):\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        dm = DataMetrics(o_schema, lineage_exe, [(\"mean\", 5.42), (\"std\", 0.67)])\n",
    "        self.assertTrue(dm.to_json() == {'id': dm.id, 'metrics': {'mean': 5.42, 'std': 0.67}, 'schema': 'd25d63ce93fc6d20dbe3bc78ee3c9253', 'lineage_execution': lineage_exe.id} and \n",
    "                          json.dumps(dm) == '{\"id\": \"' + dm.id + '\", \"metrics\": {\"mean\": 5.42, \"std\": 0.67}, \"schema\": \"d25d63ce93fc6d20dbe3bc78ee3c9253\", \"lineage_execution\": \"' + lineage_exe.id + '\"}')\n",
    "    \n",
    "    def test_to_complete_json(self):\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        dm = DataMetrics(o_schema, lineage_exe, [(\"mean\", 5.42), (\"std\", 0.67)])\n",
    "        self.assertEqual(dm.to_complete_json(), {'id': dm.id, 'metrics': {'mean': 5.42, 'std': 0.67}, 'schema': {'id': 'd25d63ce93fc6d20dbe3bc78ee3c9253', 'fields': {'in': 'float64', 'out': 'float64'}, 'data_source': {'id': 'b17989dead61b8ff3d3a527b624c73db', 'location': 'extension_doble', 'format': 'csv', 'type': 'File'}}, 'lineage_execution': {'id': lineage_exe.id, 'lineage': {'id': '6c6b2412a3f1dafa2deb6d48c042d819', 'output_schema': 'd25d63ce93fc6d20dbe3bc78ee3c9253', 'input_schemas_mapping': {'7cb6bb065abd790fda4b7e922857d78b': [{'in': ['in'], 'out': ['out']}, {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}}], '7cb6bb065abd790fda4b7e922857d78b_2': [{'in': ['in'], 'out': ['out']}, {'id': '7cb6bb065abd790fda4b7e922857d78b', 'fields': {'in': 'int64', 'out': 'int64'}, 'data_source': {'id': '0157a60140d093df8270457e485049da', 'location': 'doble', 'format': 'csv', 'type': 'File'}}]}}, 'application_execution': {'id': app_exe.id, 'application_version': {'id': '397343e65b1cd68a37d18e09c203b5bf', 'version': '1.0', 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'application_repository': {'id': '2a4cefc59444a3dac2df584d70730523', 'location': 'igmarco/DOTKit.git', 'application': {'id': '3061a641cb7c5f8180c22fab74175d00', 'name': 'App', 'owner': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}, 'author': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}}}, 'user': {'do_category': 'User', 'id': '6591935a79dc4b03f8b58c5e79d01273', 'name': 'igmarco'}, 'start_time': app_exe.start_time}, 'start_time': lineage_exe.start_time}})\n",
    "    \n",
    "    def test_dump(self):\n",
    "        file = open(\"DOFile.txt\", \"w\")\n",
    "        i_ds = DataSource(\"doble\", 'csv')\n",
    "        o_ds = DataSource(\"extension_doble\", 'csv')\n",
    "        i_schema = Schema([(\"in\",\"int64\"),(\"out\",\"int64\")], i_ds)\n",
    "        o_schema = Schema([(\"in\",\"float64\"),(\"out\",\"float64\")], o_ds)\n",
    "        lineage = Lineage(o_schema, Lineage.generate_direct_mapping(o_schema, [i_schema, i_schema]))\n",
    "        user = User(\"igmarco\")\n",
    "        app = Application(\"App\", user)\n",
    "        app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "        app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "        app_exe = ApplicationExecution(app_version, user)\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        dm = DataMetrics(o_schema, lineage_exe, [(\"mean\", 5.42), (\"std\", 0.67)])\n",
    "        dm.dump(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open('DOFile.txt', 'r')\n",
    "        file_contents = file.read()\n",
    "        file.close()\n",
    "\n",
    "        self.assertEqual(file_contents, '{\"id\": \"' + dm.id + '\", \"metrics\": {\"mean\": 5.42, \"std\": 0.67}, \"schema\": \"d25d63ce93fc6d20dbe3bc78ee3c9253\", \"lineage_execution\": \"' + lineage_exe.id + '\"}\\n\\n')\n",
    "\n",
    "# unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb216b-8f4f-4d42-a614-07fa70283fa9",
   "metadata": {},
   "source": [
    "### Ejecución de Tests Unitarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59bb08b2-26fe-4a53-9731-2915546f90d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_dump (__main__.Test_Application.test_dump) ... ok\n",
      "test_init1 (__main__.Test_Application.test_init1) ... ok\n",
      "test_init2 (__main__.Test_Application.test_init2) ... ok\n",
      "test_to_complete_json (__main__.Test_Application.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_Application.test_to_json) ... ok\n",
      "test_dump (__main__.Test_ApplicationExecution.test_dump) ... ok\n",
      "test_init (__main__.Test_ApplicationExecution.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_ApplicationExecution.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_ApplicationExecution.test_to_json) ... ok\n",
      "test_dump (__main__.Test_ApplicationRepository.test_dump) ... ok\n",
      "test_init1 (__main__.Test_ApplicationRepository.test_init1) ... ok\n",
      "test_init2 (__main__.Test_ApplicationRepository.test_init2) ... ok\n",
      "test_to_complete_json (__main__.Test_ApplicationRepository.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_ApplicationRepository.test_to_json) ... ok\n",
      "test_dump (__main__.Test_ApplicationVersion.test_dump) ... ok\n",
      "test_init1 (__main__.Test_ApplicationVersion.test_init1) ... ok\n",
      "test_init2 (__main__.Test_ApplicationVersion.test_init2) ... ok\n",
      "test_to_complete_json (__main__.Test_ApplicationVersion.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_ApplicationVersion.test_to_json) ... ok\n",
      "test_dump (__main__.Test_DataMetrics.test_dump) ... ok\n",
      "test_init (__main__.Test_DataMetrics.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_DataMetrics.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_DataMetrics.test_to_json) ... ok\n",
      "test_dump (__main__.Test_DataSource.test_dump) ... ok\n",
      "test_exists1 (__main__.Test_DataSource.test_exists1) ... ok\n",
      "test_exists2 (__main__.Test_DataSource.test_exists2) ... ok\n",
      "test_init (__main__.Test_DataSource.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_DataSource.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_DataSource.test_to_json) ... ok\n",
      "test_add_allowed_purpose (__main__.Test_Host.test_add_allowed_purpose) ... ok\n",
      "test_dump (__main__.Test_Host.test_dump) ... ok\n",
      "test_init1 (__main__.Test_Host.test_init1) ... ok\n",
      "test_init2 (__main__.Test_Host.test_init2) ... ok\n",
      "test_init3 (__main__.Test_Host.test_init3) ... ok\n",
      "test_init4 (__main__.Test_Host.test_init4) ... ok\n",
      "test_init5 (__main__.Test_Host.test_init5) ... ok\n",
      "test_remove_allowed_purpose (__main__.Test_Host.test_remove_allowed_purpose) ... ok\n",
      "test_replace_allowed_purpose1 (__main__.Test_Host.test_replace_allowed_purpose1) ... ok\n",
      "test_replace_allowed_purpose2 (__main__.Test_Host.test_replace_allowed_purpose2) ... ok\n",
      "test_to_complete_json (__main__.Test_Host.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_Host.test_to_json) ... ok\n",
      "test_dump (__main__.Test_Lineage.test_dump) ... ok\n",
      "test_get_schema_ids_list (__main__.Test_Lineage.test_get_schema_ids_list) ... ok\n",
      "test_init (__main__.Test_Lineage.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_Lineage.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_Lineage.test_to_json) ... ok\n",
      "test_dump (__main__.Test_LineageExecution.test_dump) ... ok\n",
      "test_init (__main__.Test_LineageExecution.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_LineageExecution.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_LineageExecution.test_to_json) ... ok\n",
      "test_dump (__main__.Test_Schema.test_dump) ... ok\n",
      "test_extract_fields_from_dataframe (__main__.Test_Schema.test_extract_fields_from_dataframe) ... ok\n",
      "test_init (__main__.Test_Schema.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_Schema.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_Schema.test_to_json) ... ok\n",
      "test_dump (__main__.Test_User.test_dump) ... ok\n",
      "test_init (__main__.Test_User.test_init) ... ok\n",
      "test_to_complete_json (__main__.Test_User.test_to_complete_json) ... ok\n",
      "test_to_json (__main__.Test_User.test_to_json) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 59 tests in 0.074s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2a87efa79b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44847f4e-0c43-433b-bb94-b2ed5612f906",
   "metadata": {},
   "source": [
    "## Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29eeb8-89ae-4051-82a9-5ef9271bbcd8",
   "metadata": {},
   "source": [
    "### Schema DF functions decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dbe4a49-3c72-44d2-804f-61ee2447f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaDecorator(DODecorator):\n",
    "    \n",
    "    def __init__(self, decorated_entity: DOEntity):\n",
    "        super().__init__(decorated_entity)\n",
    "        \n",
    "    def get_fold_id(self) -> str:\n",
    "        if isinstance(self.decorated_entity, DODecorator):\n",
    "            return self.decorated_entity.get_fold_id() + 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def get_schema_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Crea un DataFrame con la información del esquema de la entidad.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Un DataFrame con columnas 'schema_in' y 'schema_out'.\n",
    "        \"\"\"\n",
    "        # Verificar que la entidad decorada sea una instancia de Schema\n",
    "        if not self.get_base_entity_type() != type(Schema): \n",
    "            raise ValueError(\"La entidad decorada no cuenta como Schema\")\n",
    "        \n",
    "        # Obtener los campos de la entidad decorada\n",
    "        fields = self.decorated_entity.get_fields()\n",
    "        \n",
    "        # Crear el DataFrame\n",
    "        schema_df = pd.DataFrame(fields, columns=[\"schema_in\", \"schema_out\"])\n",
    "        \n",
    "        return schema_df\n",
    "    \n",
    "    # GETTERS - SETTERS\n",
    "    def get_fields(self) -> str:\n",
    "        return self.decorated_entity.get_fields()\n",
    "    \n",
    "    def get_data_source(self) -> str:\n",
    "        return  self.decorated_entity.get_data_source()\n",
    "    \n",
    "    def set_fields(self, fields: list[tuple[str, str]]) -> None:\n",
    "         self.decorated_entity.set_fields(fields)\n",
    "    \n",
    "    def set_data_source(self, data_source: DataSource) -> None:\n",
    "         self.decorated_entity.set_data_source(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76b661b7-b55a-47ab-91b6-5174492eba3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Schema'>\n",
      "<class '__main__.Schema'>\n",
      "  schema_in  schema_out\n",
      "0        in   double_in\n",
      "1       out  double_out\n",
      "  schema_in  schema_out\n",
      "0        in   double_in\n",
      "1       out  double_out\n"
     ]
    }
   ],
   "source": [
    "ds = DataSource(\"doble\", 'csv')\n",
    "schema = Schema([(\"in\",\"double_in\"),(\"out\",\"double_out\")], ds)\n",
    "decorated_sch1 = SchemaDecorator(schema)\n",
    "decorated_sch2 = SchemaDecorator(decorated_sch1)\n",
    "\n",
    "print(decorated_sch1.get_base_entity_type())\n",
    "print(decorated_sch2.get_base_entity_type())\n",
    "\n",
    "print(decorated_sch1.get_schema_df())\n",
    "print(decorated_sch2.get_schema_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5c3dc-29e3-46fc-9968-b62fa972257d",
   "metadata": {},
   "source": [
    "## High-Level tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94083e6-fba2-446b-8e69-615d633de382",
   "metadata": {},
   "source": [
    "### DataFrame Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb116529-fa76-4c07-ae09-7f79bee79d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "original_read_csv = pd.read_csv\n",
    "original_to_csv = pd.DataFrame.to_csv\n",
    "original_concat = pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c0deae3-f7e2-4e68-ad9b-18e38ad6bd13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DODataFrame:\n",
    "    df: pd.DataFrame\n",
    "    ds: DataSource\n",
    "    schema: Schema\n",
    "    app_exe: ApplicationExecution\n",
    "    df_input: list[pd.DataFrame]\n",
    "    ds_input: list[DataSource]\n",
    "    schema_input: list[Schema]\n",
    "\n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame, ds: DataSource, schema: Schema, app_exe: ApplicationExecution,\n",
    "                 df_input: list[pd.DataFrame] = [], ds_input: list[DataSource] = [], schema_input: list[Schema] = []) -> None:\n",
    "        self.df = df\n",
    "        self.ds = ds\n",
    "        self.schema = schema\n",
    "        self.app_exe = app_exe\n",
    "        self.df_input = df_input if df_input is not None else []\n",
    "        self.ds_input = ds_input if ds_input is not None else []\n",
    "        self.schema_input = schema_input if schema_input is not None else []\n",
    "\n",
    "    def astype(self, *args, **kwargs):\n",
    "        df = pd.DataFrame.astype(self.df, *args, **kwargs)\n",
    "        return DODataFrame(df, self.ds, self.schema, self.df_input, self.ds_input, self.schema_input)\n",
    "\n",
    "    def to_csv(self, *args, **kwargs):\n",
    "        r = original_to_csv(self.df, *args, **kwargs)\n",
    "        file_name = args[0][0:args[0].rfind('.')]\n",
    "        file_format = args[0][args[0].rfind('.') + 1:]\n",
    "        ds = DataSource(file_name, file_format)\n",
    "        print(json.dumps(ds))\n",
    "        schema = Schema(Schema.extract_fields_from_dataframe(self.df), ds)\n",
    "        print(json.dumps(schema))\n",
    "        lineage = Lineage(schema,Lineage.generate_direct_mapping(schema, self.schema_input))\n",
    "        print(json.dumps(lineage))\n",
    "        lineage_exe = LineageExecution(lineage, app_exe)\n",
    "        print(json.dumps(lineage_exe))\n",
    "        for (df_l, schema_l) in zip(self.df_input, self.schema_input):\n",
    "            ms = DataMetrics(schemal, lineage_exe, DataMetrics.extract_metrics_from_dataframe(df_l))\n",
    "            print(json.dumps(ms))\n",
    "        ms = DataMetrics(schema, lineage_exe, DataMetrics.extract_metrics_from_dataframe(self.df))\n",
    "        print(json.dumps(ms))\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1406bc24-602a-4dfc-94c0-e1858da64bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_csv_with_do(app_exe, *args, **kwargs):\n",
    "    df = original_read_csv(*args, **kwargs)\n",
    "    file_name = args[0][0:args[0].rfind('.')]\n",
    "    file_format = args[0][args[0].rfind('.') + 1:]\n",
    "    ds = DataSource(file_name, file_format)\n",
    "    print(json.dumps(ds))\n",
    "    sc = Schema(Schema.extract_fields_from_dataframe(df), ds)\n",
    "    print(json.dumps(sc))\n",
    "    dodf = DODataFrame(df, ds, sc, app_exe)\n",
    "    return dodf\n",
    "\n",
    "\n",
    "def concat_with_do(app_exe, *args):\n",
    "    df_list = []\n",
    "    ds_list = []\n",
    "    sc_list = []\n",
    "    for i in args[0]:\n",
    "        df_list.append(i.df)\n",
    "        ds_list.append(i.ds)\n",
    "        sc_list.append(i.schema)\n",
    "    df = original_concat(df_list)\n",
    "    dodf = DODataFrame(df, None, None, app_exe, df_list, ds_list, sc_list)\n",
    "    return dodf\n",
    "\n",
    "\n",
    "pd.read_csv = read_csv_with_do\n",
    "pd.concat = concat_with_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3adecbab-ea14-4c17-bb8d-4aeccb2340d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"021fcc65f540eae3907b45146676e0c8\", \"location\": \"double\", \"format\": \"csv\", \"type\": \"File\"}\n",
      "{\"id\": \"06d5551b3884c41ffddeea05d32b9ba9\", \"fields\": {\"in\": \"int32\", \"out\": \"int32\"}, \"data_source\": \"021fcc65f540eae3907b45146676e0c8\"}\n",
      "{\"id\": \"021fcc65f540eae3907b45146676e0c8\", \"location\": \"double\", \"format\": \"csv\", \"type\": \"File\"}\n",
      "{\"id\": \"06d5551b3884c41ffddeea05d32b9ba9\", \"fields\": {\"in\": \"int32\", \"out\": \"int32\"}, \"data_source\": \"021fcc65f540eae3907b45146676e0c8\"}\n",
      "{\"id\": \"fd43d2c111200bba0c36f7ec50596c00\", \"location\": \"double_concat\", \"format\": \"csv\", \"type\": \"File\"}\n",
      "{\"id\": \"56f0b7204645c195b92f194e4f64d15a\", \"fields\": {\"in\": \"int32\", \"out\": \"int32\"}, \"data_source\": \"fd43d2c111200bba0c36f7ec50596c00\"}\n",
      "{\"id\": \"6d060f80c146866a74db2dbb74cf6f9b\", \"output_schema\": \"56f0b7204645c195b92f194e4f64d15a\", \"input_schemas_mapping\": {}}\n",
      "{\"id\": \"3f931d5df3a4512eed1596522be8a1b3\", \"lineage\": \"6d060f80c146866a74db2dbb74cf6f9b\", \"application_execution\": \"b76c0e39eb3a4be1a55457b0ffb34e51\", \"start_time\": \"2024-10-06T15:05:12.503285\"}\n",
      "{\"id\": \"72b6ff8ed4f5313d2b9313f9e5b670bd\", \"metrics\": {\"out.count\": 10.0, \"out.mean\": 6.0, \"out.std\": 2.9814239699997196, \"out.min\": 2.0, \"out.25%\": 4.0, \"out.50%\": 6.0, \"out.75%\": 8.0, \"out.max\": 10.0}, \"schema\": \"56f0b7204645c195b92f194e4f64d15a\", \"lineage_execution\": \"3f931d5df3a4512eed1596522be8a1b3\"}\n"
     ]
    }
   ],
   "source": [
    "user = User(\"igmarco\")\n",
    "app = Application(\"App\", user)\n",
    "app_repo = ApplicationRepository(app, \"igmarco/DOTKit.git\", \"Git\", user)\n",
    "app_version = ApplicationVersion(app_repo, \"1.0\", user)\n",
    "app_exe = ApplicationExecution(app_version, user)\n",
    "\n",
    "double1 = pd.read_csv(\n",
    "    app_exe,\n",
    "    \"double.csv\",\n",
    "    dtype={\"in\": \"int32\", \"out\": \"int32\"},\n",
    ")\n",
    "double2 = pd.read_csv(\n",
    "    app_exe,\n",
    "    \"double.csv\",\n",
    "    dtype={\"in\": \"int32\", \"out\": \"int32\"},\n",
    ")\n",
    "\n",
    "\n",
    "double_concat = pd.concat(app_exe, [double1, double2]) \\\n",
    "    .astype({\"in\": \"int32\", \"out\": \"int32\"})\n",
    "double_concat.to_csv(\n",
    "    \"double_concat.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8026e6-2029-47a6-b18a-a01463805d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
